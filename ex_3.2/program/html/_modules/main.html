
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>main &#8212; Tutorial 3  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for main</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright 2019 Christian Henning, Alexander Meulemans</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Controller for simulations</span>
<span class="sd">--------------------------</span>

<span class="sd">The module :mod:`main` is an executable script that controls the simulations</span>
<span class="sd">(i.e., the training of regression tasks).</span>

<span class="sd">For more usage information, please check out</span>

<span class="sd">.. code-block:: console</span>

<span class="sd">  $ python3 main --help</span>

<span class="sd">There are is one dataset we want to train on:</span>


<span class="sd">1D polynomial regression</span>
<span class="sd">^^^^^^^^^^^^^^^^^^^^^^^^</span>

<span class="sd">In case of 1D regression tasks, the result can be visualized to a human, who</span>
<span class="sd">can assess the quality of the optimizer.</span>

<span class="sd">An example 1D regression task can be retrieved using the function</span>
<span class="sd">:func:`lib.utils.regression_cubic_poly`.</span>

<span class="sd">In this exercise, we want to understand the difference between standart</span>
<span class="sd">maximum likelihood and a bayesian treatment of learning. For the latter, we need</span>
<span class="sd">to approximate the intractable weight posterior to do inference. </span>
<span class="sd">First, we take a closer look at:</span>

<span class="sd">Maximum likelihood</span>
<span class="sd">^^^^^^^^^^^^^^^^^^</span>

<span class="sd">Juhuu! </span>
<span class="sd">For this part, you don&#39;t have to programm anything to make the script work.</span>

<span class="sd">In the case of maximum likelihodd, we train a standart neural network </span>
<span class="sd">with backpropagation to minimize a certain loss. We obtain one set of weights</span>
<span class="sd">that supposedly solves the problem.</span>

<span class="sd">To visualize and run the training, execute </span>

<span class="sd">.. code-block:: console</span>

<span class="sd">  $ python3 main --show_plot</span>
<span class="sd">  </span>
<span class="sd">This script can be used to train on this dataset via the option</span>
<span class="sd">option.</span>

<span class="sd">.. code-block:: console</span>

<span class="sd">  $ python main.py --show_plot --data_random_seed 753</span>

<span class="sd">Furthermore, you can train on this dataset also via the option</span>
<span class="sd">``--random_seed``.</span>

<span class="sd">.. code-block:: console</span>

<span class="sd">  $ python main.py --show_plot --random_seed 656</span>

<span class="sd">These random seed options change the generation of the training data a little</span>
<span class="sd">or how your initial weights, the training starting points, are determined. </span>

<span class="sd">You can think of these random seeds, as specification how and when data was </span>
<span class="sd">collected and in what state your algorithm was when we started training. </span>
<span class="sd">(One could even imagine that the algorithm was already trained on another task.)</span>

<span class="sd">Oberserve the difference when you change one/both of the seeds (753, 656 above) </span>
<span class="sd">to other numbers and describe it and the possible shortcomings of </span>
<span class="sd">maximum likelihood (TODO).</span>


<span class="sd">Bayes-by-Backprop</span>
<span class="sd">^^^^^^^^^^^^^^^^^^</span>

<span class="sd">In the case of bayes-by-Backprop, to run the training, execute </span>

<span class="sd">.. code-block:: console</span>

<span class="sd">  $ python3 main --bbb</span>

<span class="sd">Add to visualise ``--random_seed``.</span>


<span class="sd">.. autosummary::</span>

<span class="sd">    main.run</span>
<span class="sd">    main.train</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">lib.mlp</span> <span class="k">import</span> <span class="n">MLP</span>
<span class="kn">from</span> <span class="nn">lib</span> <span class="k">import</span> <span class="n">utils</span>

<div class="viewcode-block" id="test"><a class="viewcode-back" href="../modules.html#main.test">[docs]</a><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;test a train network by computing the MSE on the test set.</span>

<span class="sd">    Args:</span>
<span class="sd">        (....): See docstring of function :func:`train`.</span>
<span class="sd">        test_loader (torch.utils.data.DataLoader): The data handler for</span>
<span class="sd">            test data.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (float): The mean-squared error for the test set ``test_loader`` when</span>
<span class="sd">        using the network ``net``. Note, the ``Function``</span>
<span class="sd">        :func:`lib.backprop_functions.mse_loss` is used to compute the MSE</span>
<span class="sd">        value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#######################################################################</span>
    <span class="c1">### NOTE, the function `mse_loss` divides by the current batch size. In</span>
    <span class="c1">### order to compute the MSE across several mini-batches, one needs to</span>
    <span class="c1">### correct for this behavior.</span>
    <span class="c1">#######################################################################</span>

    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">mse</span> <span class="o">=</span> <span class="mf">0.</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">batch_size</span>

            <span class="n">predictions</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="n">mse</span> <span class="o">+=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="n">mse</span> <span class="o">/=</span> <span class="n">num_samples</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test MSE: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mse</span><span class="p">))</span>

    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">mse</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span></div>

<div class="viewcode-block" id="train"><a class="viewcode-back" href="../modules.html#main.train">[docs]</a><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">net</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Train the given network on the given (regression) dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        args (argparse.Namespace): The command-line arguments.</span>
<span class="sd">        device: The PyTorch device to be used.</span>
<span class="sd">        train_loader (torch.utils.data.DataLoader): The data handler for</span>
<span class="sd">            training data.</span>
<span class="sd">        net: The neural network.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training network ...&#39;</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
                                <span class="n">momentum</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">predictions</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">bbb</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">bbb</span><span class="p">:</span>
                
                <span class="n">nll</span><span class="p">,</span> <span class="n">kl</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">computeELBO</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> 
                                                                          <span class="n">args</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">nll</span> <span class="o">+</span> <span class="n">kl</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kl</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1"> -- loss = </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">loss</span> <span class="o">-</span> <span class="n">kl</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">bbb</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1"> -- prior-matching-loss = </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">kl</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training network ... Done&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="run"><a class="viewcode-back" href="../modules.html#main.run">[docs]</a><span class="k">def</span> <span class="nf">run</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Run the script.</span>

<span class="sd">    - Parsing command-line arguments</span>
<span class="sd">    - Creating synthetic regression data</span>
<span class="sd">    - Initiating training process</span>
<span class="sd">    - Testing final network</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">### Parse CLI arguments.</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;Nonlinear regression with &#39;</span> <span class="o">+</span>
                                     <span class="s1">&#39;neural networks.&#39;</span><span class="p">)</span>

    <span class="n">tgroup</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s1">&#39;Training options&#39;</span><span class="p">)</span>
    <span class="n">tgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--epochs&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Number of training epochs. &#39;</span> <span class="o">+</span>
                             <span class="s1">&#39;Default: </span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">tgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch_size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Training batch size. Default: </span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">tgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--lr&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Learning rate of optimizer. Default: &#39;</span> <span class="o">+</span>
                             <span class="s1">&#39;</span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">tgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--momentum&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Momentum of the optimizer. &#39;</span> <span class="o">+</span>
                             <span class="s1">&#39;Default: </span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">sgroup</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s1">&#39;Network options&#39;</span><span class="p">)</span>
    <span class="n">sgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--num_hidden&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Number of hidden layer in the (student) &#39;</span> <span class="o">+</span>
                             <span class="s1">&#39;network. Default: </span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">sgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--size_hidden&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Number of units in each hidden layer of the &#39;</span> <span class="o">+</span>
                             <span class="s1">&#39;(student) network. Default: </span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">sgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--num_train_samples&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Number of data training points.&#39;</span><span class="p">)</span>

    <span class="n">mgroup</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s1">&#39;Miscellaneous options&#39;</span><span class="p">)</span>
    <span class="n">mgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--use_cuda&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Flag to enable GPU usage.&#39;</span><span class="p">)</span>
    <span class="n">mgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--random_seed&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Random seed. Default: </span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">mgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--data_random_seed&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">metavar</span><span class="o">=</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Data random seed. Default: </span><span class="si">%(default)s</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">mgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--dont_show_plot&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_false&#39;</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Dont show the final regression results as plot.&#39;</span> <span class="o">+</span>
                             <span class="s1">&#39;Note, only applies to 1D regression tasks.&#39;</span><span class="p">)</span>

    <span class="n">bgroup</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s1">&#39;Bayes by Backprop options&#39;</span><span class="p">)</span>
    <span class="n">bgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--bbb&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Start training of BbB.&#39;</span><span class="p">)</span>
    <span class="n">bgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--prior_variance&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Variance of the Gaussian prior.&#39;</span><span class="p">)</span>
    <span class="n">bgroup</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--weight_samples&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Number of weight samples used.&#39;</span><span class="p">)</span>
                        

    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="c1">### Ensure deterministic computation.</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="c1"># Ensure that runs are reproducible even on GPU. Note, this slows down</span>
    <span class="c1"># training!</span>
    <span class="c1"># https://pytorch.org/docs/stable/notes/randomness.html</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">use_cuda</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">use_cuda</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Using cuda: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">use_cuda</span><span class="p">))</span>

    <span class="c1">### Generate datasets and data handlers.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;### Learning to regress a 1D cubic polynomial ###&#39;</span><span class="p">)</span>
    <span class="n">n_in</span> <span class="o">=</span> <span class="n">n_out</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">regression_cubic_poly</span><span class="p">(</span><span class="n">rseed</span><span class="o">=</span> \
                        <span class="n">args</span><span class="o">.</span><span class="n">data_random_seed</span><span class="p">,</span> <span class="n">num_train</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_train_samples</span><span class="p">)</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">RegressionDataset</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">),</span>
                              <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">RegressionDataset</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">),</span>
                             <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1">### Generate network.</span>
    <span class="n">n_hidden</span> <span class="o">=</span> <span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">size_hidden</span><span class="p">]</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">num_hidden</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">n_in</span><span class="o">=</span><span class="n">n_in</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="n">n_out</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1">### Train network.</span>
    <span class="n">train</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">net</span><span class="p">)</span>

    <span class="c1">### Test network.</span>
    <span class="n">test</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">net</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dont_show_plot</span> <span class="ow">and</span> <span class="n">n_in</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">n_out</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">plot_predictions</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span></div>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run</span><span class="p">()</span>


</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Tutorial 3</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Johannes von Oswald, Christian Henning.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.2.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>